{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- leectura y guardado de los documentos en un data frame de pandas.\n",
    "def get_mourning_df(create_new_file, balance_data, lematizacion, training):\n",
    "    from gensim.utils import any2unicode as unicode\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from sklearn.utils import resample\n",
    "    import os, re, sys, pandas, unidecode\n",
    "\n",
    "    mourning_folder = '../datos mourning'\n",
    "    mourning_df_path = mourning_folder + '/dataset listo/mourning_full_df.csv'\n",
    "    mourning_df = pandas.DataFrame(columns=['text', 'lang', 'mourning'])\n",
    "\n",
    "    if create_new_file == 0 and os.path.exists(mourning_df_path) == True:\n",
    "        print('Cargando datos')\n",
    "        mourning_df = pandas.read_csv(mourning_df_path, encoding='utf8', dtype=str, engine='python')\n",
    "\n",
    "    elif create_new_file == 1 or os.path.exists(mourning_df_path) == False:\n",
    "        path, subfolders, files_list = list(os.walk(mourning_folder))[0]\n",
    "        files_list.sort()\n",
    "        for i in range(len(files_list)):\n",
    "            sys.stdout.write(\n",
    "                \"\\rPreparando dataframe \" + str(round(((i + 1) / (len(files_list))) * 100, 2)) + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            file_name, file_ext = files_list[i].split(\".\")\n",
    "\n",
    "            if file_ext == 'csv':\n",
    "                file_path = path + \"/\" + file_name + \".\" + file_ext\n",
    "                df = pandas.read_csv(file_path, encoding='utf8', dtype=str, engine='python')\n",
    "                numero_de_archivo = int(file_name.split(\"_\")[0])\n",
    "\n",
    "                if numero_de_archivo == 1 or numero_de_archivo == 2:\n",
    "                    df = df.filter(['text', 'lang', 'mourning'])\n",
    "                    df['mourning'] = df.mourning.map({'4': '0', '1': '1'})\n",
    "                    mourning_df = mourning_df.append(df)\n",
    "\n",
    "                if numero_de_archivo == 3:\n",
    "                    df = df.filter(['text', 'lang', 'tag'])\n",
    "                    df.columns = ['text', 'lang', 'mourning']\n",
    "                    df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                    mourning_df = mourning_df.append(df)\n",
    "\n",
    "                if numero_de_archivo == 4:\n",
    "                    df = df.filter(['tweet', 'lang', 'mourning'])\n",
    "                    df.columns = ['text', 'lang', 'mourning']\n",
    "                    df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                    mourning_df = mourning_df.append(df)\n",
    "\n",
    "        del df\n",
    "        print(\"\")\n",
    "        mourning_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rNormalizacion de datos completada al \" + str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2)) +\n",
    "                \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            mourning_df.at[i, 'text'] = (\n",
    "                re.sub(' +', ' ', re.sub(\"http\\S+\", \"\", re.sub('\\s+', ' ', str(mourning_df.at[i, 'text']))))\n",
    "            ).strip()\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    mourning_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    mourning_df = mourning_df.loc[mourning_df['mourning'].isin(['1', '0'])]\n",
    "    mourning_df = mourning_df.loc[mourning_df['lang'].isin(['es', 'en'])]\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "    mourning_df.to_csv(mourning_df_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    if training == 1 and os.path.exists('./dataset etiquetado modelos/taged_tweets_sample.csv'):\n",
    "        print(\"Incrementando datos con dataset etiquetado por modelos\")\n",
    "        df = pandas.read_csv('./dataset etiquetado modelos/taged_tweets_sample.csv',\n",
    "                             encoding='utf8', dtype=str, engine='python')\n",
    "        df = df.filter(['text', 'lang', 'mourning'])\n",
    "        mourning_df = mourning_df.append(df)\n",
    "        mourning_df.reset_index(drop=True, inplace=True)\n",
    "        del df\n",
    "\n",
    "    if lematizacion == 1:\n",
    "        stemmer_en = SnowballStemmer('english')\n",
    "        stemmer_es = SnowballStemmer('spanish')\n",
    "\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rLematizando \" + str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2)) + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if mourning_df.at[i, 'text'] is str and mourning_df.at[i, 'lang'] == 'es':\n",
    "                mourning_df.at[i, 'text'] = stemmer_es.stem(unidecode.unidecode(\n",
    "                    unicode(mourning_df.at[i, 'text'].lower(), \"utf-8\"))\n",
    "                )\n",
    "\n",
    "            elif mourning_df.at[i, 'text'] is str and mourning_df.at[i, 'lang'] == 'en':\n",
    "                mourning_df.at[i, 'text'] = stemmer_en.stem(unidecode.unidecode(\n",
    "                    unicode(mourning_df.at[i, 'text'].lower(), \"utf-8\"))\n",
    "                )\n",
    "\n",
    "        print(\"\\nLematizacion finalizada\")\n",
    "\n",
    "    if balance_data == 1:\n",
    "        print(\"Balanceando datos\")\n",
    "        mourning_df[\"Sello\"] = 0\n",
    "\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rCreando sellos de balanceamiento \" +\n",
    "                str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2))\n",
    "                + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            mourning_df.at[i, 'sello'] = str(mourning_df.at[i, 'lang']) + '_' + str(mourning_df.at[i, 'mourning'])\n",
    "\n",
    "        min_len1 = int(min(mourning_df['sello'].value_counts()))\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Balanceando\")\n",
    "\n",
    "        df_0 = resample(mourning_df[mourning_df.sello == 'es_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_1 = resample(mourning_df[mourning_df.sello == 'es_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_2 = resample(mourning_df[mourning_df.sello == 'en_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_3 = resample(mourning_df[mourning_df.sello == 'en_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "\n",
    "        mourning_df = pandas.concat([df_0, df_1, df_2, df_3])\n",
    "\n",
    "        print(\"Eliminando sellos de balanceamiento\")\n",
    "\n",
    "        mourning_df = mourning_df.filter(['text', 'lang', 'mourning'])\n",
    "        print(\"Datos entregados\")\n",
    "        mourning_df.reset_index(drop=True, inplace=True)\n",
    "        return mourning_df\n",
    "\n",
    "    elif balance_data == 0:\n",
    "        print(\"Datos entregados\")\n",
    "        mourning_df.reset_index(drop=True, inplace=True)\n",
    "        return mourning_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweets en el dataframe original: 16140\n"
     ]
    }
   ],
   "source": [
    "df = get_mourning_df(0,)\n",
    "print(\"\\nTweets en el dataframe original: \" + str(main_dataframe.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets en el dataframe balanceado: 8010\n"
     ]
    }
   ],
   "source": [
    "# ---------------- balanceamiento del dataset.\n",
    "min_len = int(min(main_dataframe['sentiment'].value_counts()))\n",
    "df_0 = resample(main_dataframe[main_dataframe.sentiment == 0], replace=False, n_samples=min_len)\n",
    "df_1 = resample(main_dataframe[main_dataframe.sentiment == 1], replace=False, n_samples=min_len)\n",
    "df_2 = resample(main_dataframe[main_dataframe.sentiment == 2], replace=False, n_samples=min_len)\n",
    "new_main_dataframe = pd.concat([df_0, df_1, df_2])\n",
    "del main_dataframe\n",
    "\n",
    "print(\"Tweets en el dataframe balanceado: \" + str(new_main_dataframe.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- construccion de modelo de bolsa de palabras.\n",
    "count_vector = CountVectorizer()\n",
    "features = count_vector.fit_transform(new_main_dataframe['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- Separacion en data y labels de entrnamiento.\n",
    "data_train, data_test, label_train, label_test = train_test_split(\n",
    "    features,\n",
    "    new_main_dataframe['sentiment']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=8,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.0, n_estimators=6, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---------------- entrenamiento del modelo.\n",
    "modelo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=8), n_estimators=6)\n",
    "modelo.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- implementacion del modelo.\n",
    "predictions0 = modelo.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos para la prueba: 2003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- resultados del modelo.\n",
    "datos_totales_prueba = len(label_test)\n",
    "print(\"Numero de datos para la prueba: \" + str(datos_totales_prueba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de aciertos totales: 1259\n",
      "Precision total: 0.6285571642536195\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(label_test, predictions0)\n",
    "aciertos = sum([matrix[i][i] for i in range(matrix.shape[0])])\n",
    "precision = aciertos / datos_totales_prueba\n",
    "print(\"Numero de aciertos totales: \" + str(aciertos))\n",
    "print(\"Precision total: \" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos para la prueba: 2003\n",
      "Precision promedio: 0.6274006309576078\n",
      "Recall promedio: 0.6415748275219976\n",
      "\n",
      "Matriz de confusion: \n",
      "+----------+------------+------------+-----------+\n",
      "|          |   positive |   negative |   neutral |\n",
      "+==========+============+============+===========+\n",
      "| positive |        389 |         78 |       185 |\n",
      "+----------+------------+------------+-----------+\n",
      "| negative |         70 |        393 |       195 |\n",
      "+----------+------------+------------+-----------+\n",
      "| neutral  |         84 |        132 |       477 |\n",
      "+----------+------------+------------+-----------+\n",
      "\n",
      "Metricas de desempeño: \n",
      "+----------+-------------+----------+\n",
      "|          |   precision |   recall |\n",
      "+==========+=============+==========+\n",
      "| positive |    0.596626 | 0.71639  |\n",
      "+----------+-------------+----------+\n",
      "| negative |    0.597264 | 0.651741 |\n",
      "+----------+-------------+----------+\n",
      "| neutral  |    0.688312 | 0.556593 |\n",
      "+----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def imprimir_metricas_matriz_confusion_multiclase(matrix, headers, total_datos):\n",
    "    print(\"Numero de datos para la prueba: \" + str(total_datos))\n",
    "    metrics = np.zeros([len(headers), 2])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        precision = matrix[i][i] / sum(matrix[i])\n",
    "        recoil = matrix[i][i] / sum([matrix[y][i] for y in range(matrix.shape[0])])\n",
    "        metrics[i][0] = precision\n",
    "        metrics[i][-1] = recoil\n",
    "    precision_promedio = sum([metrics[y][0] for y in range(metrics.shape[0])]) / metrics.shape[0]\n",
    "    recall_promedio = sum([metrics[y][-1] for y in range(metrics.shape[0])]) / metrics.shape[0]\n",
    "    print(\"Precision promedio: \" + str(precision_promedio))\n",
    "    print(\"Recall promedio: \" + str(recall_promedio))\n",
    "    print(\"\\nMatriz de confusion: \\n\" + str(tabulate(\n",
    "        matrix,\n",
    "        headers=headers,\n",
    "        showindex=headers,\n",
    "        tablefmt='grid')\n",
    "    ))\n",
    "    print(\"\\nMetricas de desempeño: \\n\" + str(tabulate(\n",
    "        metrics,\n",
    "        headers=['precision', 'recall'],\n",
    "        showindex=headers,\n",
    "        tablefmt='grid')\n",
    "    ))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "imprimir_metricas_matriz_confusion_multiclase(\n",
    "    matrix,\n",
    "    ['positive', 'negative', 'neutral'],\n",
    "    len(label_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de aciertos totales: 1259\n",
      "Precision total: 0.6285571642536195\n"
     ]
    }
   ],
   "source": [
    "matrix1 = confusion_matrix(label_test, predictions)\n",
    "aciertos = sum([matrix[i][i] for i in range(matrix.shape[0])])\n",
    "precision = aciertos / datos_totales_prueba\n",
    "print(\"Numero de aciertos totales: \" + str(aciertos))\n",
    "print(\"Precision total: \" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos para la prueba: 2003\n",
      "Precision promedio: 0.7002372793392242\n",
      "Recall promedio: 0.7129572792561159\n",
      "\n",
      "Matriz de confusion: \n",
      "+----------+------------+------------+-----------+\n",
      "|          |   positive |   negative |   neutral |\n",
      "+==========+============+============+===========+\n",
      "| positive |        432 |         55 |       165 |\n",
      "+----------+------------+------------+-----------+\n",
      "| negative |         48 |        463 |       147 |\n",
      "+----------+------------+------------+-----------+\n",
      "| neutral  |         67 |        117 |       509 |\n",
      "+----------+------------+------------+-----------+\n",
      "\n",
      "Metricas de desempeño: \n",
      "+----------+-------------+----------+\n",
      "|          |   precision |   recall |\n",
      "+==========+=============+==========+\n",
      "| positive |    0.662577 | 0.789762 |\n",
      "+----------+-------------+----------+\n",
      "| negative |    0.703647 | 0.729134 |\n",
      "+----------+-------------+----------+\n",
      "| neutral  |    0.734488 | 0.619976 |\n",
      "+----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def imprimir_metricas_matriz_confusion_multiclase(matrix, headers, total_datos):\n",
    "    print(\"Numero de datos para la prueba: \" + str(total_datos))\n",
    "    metrics = np.zeros([len(headers), 2])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        precision = matrix[i][i] / sum(matrix[i])\n",
    "        recoil = matrix[i][i] / sum([matrix[y][i] for y in range(matrix.shape[0])])\n",
    "        metrics[i][0] = precision\n",
    "        metrics[i][-1] = recoil\n",
    "    precision_promedio = sum([metrics[y][0] for y in range(metrics.shape[0])]) / metrics.shape[0]\n",
    "    recall_promedio = sum([metrics[y][-1] for y in range(metrics.shape[0])]) / metrics.shape[0]\n",
    "    print(\"Precision promedio: \" + str(precision_promedio))\n",
    "    print(\"Recall promedio: \" + str(recall_promedio))\n",
    "    print(\"\\nMatriz de confusion: \\n\" + str(tabulate(\n",
    "        matrix,\n",
    "        headers=headers,\n",
    "        showindex=headers,\n",
    "        tablefmt='grid')\n",
    "    ))\n",
    "    print(\"\\nMetricas de desempeño: \\n\" + str(tabulate(\n",
    "        metrics,\n",
    "        headers=['precision', 'recall'],\n",
    "        showindex=headers,\n",
    "        tablefmt='grid')\n",
    "    ))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "imprimir_metricas_matriz_confusion_multiclase(\n",
    "    matrix1,\n",
    "    ['positive', 'negative', 'neutral'],\n",
    "    len(label_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AnalisisSentimientos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import any2unicode as unicode\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.utils import resample\n",
    "import os, re, sys, pandas, unidecode, string\n",
    "\n",
    "import numpy\n",
    "import emoji\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# balance_data: 0 para retornar dataframe sin balancear o 1 para retornar\n",
    "# dataframe balanceado.\n",
    "# lematizacion: lematiza los textos usando nltk 0 para no lematizar y 1\n",
    "# para retornar el texto lematizado.\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_mourning_df(balance_data):\n",
    "    from gensim.utils import any2unicode as unicode\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from sklearn.utils import resample\n",
    "    import os, re, sys, pandas, unidecode\n",
    "\n",
    "    mourning_folder = 'entrenamiento de modelos/datos mourning'\n",
    "    mourning_df = pandas.DataFrame(columns=['text', 'lang', 'mourning'])\n",
    "    path, subfolders, files_list = list(os.walk(mourning_folder))[0]\n",
    "    files_list.sort()\n",
    "\n",
    "    for i in range(len(files_list)):\n",
    "        sys.stdout.write(\"\\rPreparando df \" + str(round(((i + 1) / (len(files_list))) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        file_name, file_ext = files_list[i].split(\".\")\n",
    "\n",
    "        if file_ext == 'csv':\n",
    "            file_path = path + \"/\" + file_name + \".\" + file_ext\n",
    "            df = pandas.read_csv(file_path, encoding='utf8', dtype=str, engine='python')\n",
    "            numero_de_archivo = int(file_name.split(\"_\")[0])\n",
    "\n",
    "            if numero_de_archivo == 1 or numero_de_archivo == 2:\n",
    "                df = df.filter(['text', 'lang', 'mourning'])\n",
    "                df['mourning'] = df.mourning.map({'4': '0', '1': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "            if numero_de_archivo == 3:\n",
    "                df = df.filter(['text', 'lang', 'tag'])\n",
    "                df.columns = ['text', 'lang', 'mourning']\n",
    "                df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "            if numero_de_archivo == 4:\n",
    "                df = df.filter(['tweet', 'lang', 'mourning'])\n",
    "                df.columns = ['text', 'lang', 'mourning']\n",
    "                df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "    del df\n",
    "    print(\"\")\n",
    "    mourning_df.dropna()\n",
    "    mourning_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    mourning_df = mourning_df.loc[mourning_df['mourning'].isin(['1', '0'])]\n",
    "    mourning_df = mourning_df.loc[mourning_df['lang'].isin(['es', 'en'])]\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for i, row in mourning_df.iterrows():\n",
    "        sys.stdout.write(\"\\rNormalizando df \" + str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        mourning_df.at[i, 'text'] = (\n",
    "            re.sub('\\s+', ' ',\n",
    "                   re.sub(' +', ' ',\n",
    "                          re.sub(\"http\\S+\", \"\",\n",
    "                                 re.sub(r'\\b(?=\\w*[j])[aeiouj]{2,}\\b', 'jajaja',\n",
    "                                        re.sub(r'[\\b@]\\w+\\s{1}', '', str(mourning_df.at[i, 'text'])\n",
    "                                               )))))).strip()\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    if balance_data == 1:\n",
    "        mourning_df[\"Sello\"] = 0\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rCreando sellos de balanceamiento \" +\n",
    "                str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2))\n",
    "                + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            mourning_df.at[i, 'sello'] = str(mourning_df.at[i, 'lang']) + '_' + str(mourning_df.at[i, 'mourning'])\n",
    "        print(\"\\nBalanceando df\")\n",
    "        min_len1 = int(min(mourning_df['sello'].value_counts()))\n",
    "        df_0 = resample(mourning_df[mourning_df.sello == 'es_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_1 = resample(mourning_df[mourning_df.sello == 'es_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_2 = resample(mourning_df[mourning_df.sello == 'en_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_3 = resample(mourning_df[mourning_df.sello == 'en_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        mourning_df = pandas.concat([df_0, df_1, df_2, df_3])\n",
    "        mourning_df = mourning_df.filter(['text', 'lang', 'mourning'])\n",
    "        mourning_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    print(\"Df mourning entregado\\n\")\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "    return mourning_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 12.34%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando df 31.97%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando df 52.17%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando df 71.91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando df 91.91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando sellos de balanceamiento 19.6%%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando sellos de balanceamiento 40.88%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando sellos de balanceamiento 60.84%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando sellos de balanceamiento 81.66%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Df mourning entregado\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = get_mourning_df(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------\n",
    "#Se separa la data por idiomas\n",
    "#--------------------\n",
    "\n",
    "df_en = df[df['lang']==\"en\"]\n",
    "df_es = df[df['lang']==\"es\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- Lexicones\n",
    "#Lectura de SentiWordNet Obtenido de \n",
    "#https://www.nltk.org/_modules/nltk/corpus/reader/sentiwordnet.html\n",
    "\n",
    "# SentiWordNet[word] = {POS,\tID,\tPosScore,\tNegScore}\n",
    "contador = 0\n",
    "SentiWordNet = dict()\n",
    "for lines in open('entrenamiento de modelos/data lexicon/SentiWordNet_3.0.0.txt'):\n",
    "    if lines.startswith('#'):\n",
    "        continue\n",
    "    line = lines.split('\\t')\n",
    "    palabra = line[4].split('#')[0]\n",
    "    if (palabra in SentiWordNet) or (palabra==''):\n",
    "        continue\n",
    "    else:\n",
    "        SentiWordNet[palabra]={'POS': line[0], 'ID': line[1], 'PosScore': line[2], 'NegScore': line[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFIN[word] = sentiment\n",
    "AFFIN = dict()\n",
    "for lines in open('entrenamiento de modelos/data lexicon/AFFIN-111.txt'):\n",
    "    AFFIN[lines.split('\\t')[0]]=(lines.split('\\t')[1]).split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "se divide es el texto del tweet mediante el uso de \n",
    "TweetTokenizer() y se normalizan las risas, se eliminan las menciones\n",
    "y se lematizan las palabras\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "def tokenizar(text, idioma):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    palabras = []\n",
    "    lema = {'es': SnowballStemmer('spanish'), 'en': SnowballStemmer('english')}\n",
    "    \n",
    "    text = re.sub(r'[\\b@]\\w+\\s{1}', '', text)#Quitar menciones\n",
    "    words = tweet_tokenizer.tokenize(text)\n",
    "    for w in words:\n",
    "        if re.match(r'\\W', w)==None:\n",
    "            \n",
    "            p = unidecode.unidecode(w).lower() #Quitar Acentos minuscula\n",
    "            p = re.sub(r'\\b(?=\\w*[j])[aeiouj]{2,}\\b', 'jajaja', p) #Normalizar Risa\n",
    "            p = re.sub(r'\\b(?=\\w*[h])[aeiouh]{2,}\\b', 'jajaja', p) #Normalizar Risa\n",
    "            p = lema[idioma].stem(p)\n",
    "            palabras.append(p)\n",
    "        elif re.match(r'#', w)!=None:\n",
    "            palabras.append(unidecode.unidecode(w).lower())\n",
    "        elif  w in emoji.UNICODE_EMOJI:\n",
    "            palabras.append(w)\n",
    "    return palabras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "se crea el lexicon basado en los tweets etiquetados para morning y no mourning\n",
    "se usa la la fórmula P = P(word|mourning)*P(word)\n",
    "\"\"\"\n",
    "\n",
    "def lexicon_mornig(df):\n",
    "    lexicon = dict()\n",
    "    morning = [[],[]] # [no morning, morning]\n",
    "    \n",
    "    cont=0\n",
    "    \n",
    "    cont_morning = dict()\n",
    "    cont_no_morning = dict()\n",
    "    cont_total = dict()\n",
    "    \n",
    "    vocabulario = set([])\n",
    "    \n",
    "    i=0\n",
    "    for index, row in df.iterrows():\n",
    "        i+=1\n",
    "        sys.stdout.write(\"\\rCreando lexicon df \" + str(round(((i) / (df.shape[0])) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        cont += 1\n",
    "                \n",
    "        palabras = tokenizar(row['text'], row['lang'])  \n",
    "        \n",
    "        vocabulario|=set(palabras)\n",
    "        morning[int(row['mourning'])].append(set(palabras))    \n",
    "        #print(row['text'])\n",
    "        #print(palabras)\n",
    "        \n",
    "    for v in morning[1]:\n",
    "        for m in v:\n",
    "            cont_morning[m]=1 if m not in cont_morning else cont_morning[m]+1\n",
    "            cont_total[m]=1 if m not in cont_total else cont_total[m]+1\n",
    "            \n",
    "    for v in morning[0]:\n",
    "        for m in v:\n",
    "            cont_no_morning[m]=1 if m not in cont_morning else cont_morning[m]+1\n",
    "            cont_total[m]=1 if m not in cont_total else cont_total[m]+1\n",
    "            \n",
    "    for w in vocabulario:\n",
    "        if cont_total[w] > 5: \n",
    "            lexicon[w]=0\n",
    "            if w in cont_no_morning:\n",
    "                lexicon[w] -= (cont_no_morning[w]/len(morning[0]))*(cont_total[w]/cont) \n",
    "                \n",
    "            if w in cont_morning:\n",
    "                lexicon[w] += (cont_morning[w]/len(morning[1]))*(cont_total[w]/cont) \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para vectorizar se reemplaza cada palabra con el valor generado del lexicón creado\n",
    "y se agregan los valores obtenido de diferentes lexicones\n",
    "\"\"\"\n",
    "\n",
    "def vectorizar(df, lexicon):    \n",
    "    print()\n",
    "    keys = tuple(lexicon.keys())\n",
    "    y = dict()\n",
    "    for a in keys:\n",
    "        y[a]=list(numpy.zeros(df.shape[0]))\n",
    "    y['SentiWordNet_neg'] = 0\n",
    "    y['SentiWordNet_pos'] = 0\n",
    "    y['AFFIN'] = 0\n",
    "    i=0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        sys.stdout.write(\"\\rVectorizando df \" + str(round(((i+1) / (df.shape[0])) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        v = dict()\n",
    "        palabras = tokenizar(row['text'], row['lang']) \n",
    "        \n",
    "        sum_swn_neg = 0\n",
    "        sum_swn_pos = 0\n",
    "        \n",
    "        affin = 0\n",
    "        \n",
    "        for w in palabras:\n",
    "            if w in lexicon:\n",
    "                y[w][i]=lexicon[w]\n",
    "                \n",
    "            if w in SentiWordNet.keys():\n",
    "                y['SentiWordNet_neg'] += float(SentiWordNet[w]['NegScore'])\n",
    "                y['SentiWordNet_pos'] += float(SentiWordNet[w]['PosScore'])\n",
    "                \n",
    "            if w in AFFIN.keys():\n",
    "                y['AFFIN'] += float(AFFIN[w])\n",
    "        i+=1\n",
    "    \n",
    "    vector = pandas.DataFrame.from_dict(y)    \n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando lexicon df 35.93%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando lexicon df 95.56%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizando df 100.0%"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Se crea el lexicón y se vectoriza los tweets en español\n",
    "\"\"\"\n",
    "\n",
    "lex_es = lexicon_mornig(df_es)\n",
    "vector_es = vectorizar(df_es, lex_es).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\"\"\"\n",
    "Se entrena el modelo K-Means y se evalúa\n",
    "\"\"\"\n",
    "\n",
    "real_es = list(df_es['mourning'])\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(vector_es)\n",
    "predic_es = model.fit_predict(vector_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predic_es</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real_es</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2097</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2490</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predic_es     0     1\n",
       "real_es              \n",
       "0          2097  2078\n",
       "1          2490  1685"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Generación de tabla pivote\"\"\"\n",
    "\n",
    "df_comparison_es = pandas.DataFrame({'predic_es': predic_es, 'real_es': real_es})\n",
    "tabla_pivot_es = pandas.crosstab(df_comparison_es['real_es'], df_comparison_es['predic_es'])\n",
    "tabla_pivot_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48      4175\n",
      "           1       0.45      0.40      0.42      4175\n",
      "\n",
      "    accuracy                           0.45      8350\n",
      "   macro avg       0.45      0.45      0.45      8350\n",
      "weighted avg       0.45      0.45      0.45      8350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\"\"\"Generación de métricas del modelo\"\"\"\n",
    "print(\"\\nResultados \")\n",
    "print(classification_report([int(i) for i in real_es], predic_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando lexicon df 100.0%\n",
      "Vectorizando df 100.0%"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Se crea el lexicón y se vectoriza los tweets en ingles\n",
    "\"\"\"\n",
    "\n",
    "lex_en = lexicon_mornig(df_en)\n",
    "vector_en = vectorizar(df_en, lex_en).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\"\"\"\n",
    "Se entrena el modelo K-Means y se evalúa\n",
    "\"\"\"\n",
    "\n",
    "real_en = list(df_en['mourning'])\n",
    "model_en = KMeans(n_clusters=2)\n",
    "model_en.fit(vector_en)\n",
    "predic_en = model_en.fit_predict(vector_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>real_en</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predic_en</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2302</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1873</td>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "real_en       0     1\n",
       "predic_en            \n",
       "0          2302  1959\n",
       "1          1873  2216"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Generación de tabla pivote\"\"\"\n",
    "df_comparison_en = pandas.DataFrame({'predic_en': predic_en, 'real_en': real_en})\n",
    "tabla_pivot = pandas.crosstab(df_comparison_en['predic_en'], df_comparison_en['real_en'])\n",
    "tabla_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.55      4175\n",
      "           1       0.54      0.53      0.54      4175\n",
      "\n",
      "    accuracy                           0.54      8350\n",
      "   macro avg       0.54      0.54      0.54      8350\n",
      "weighted avg       0.54      0.54      0.54      8350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\"\"\"Generación de métricas del modelo\"\"\"\n",
    "print(\"\\nResultados \")\n",
    "print(classification_report([int(i) for i in real_en], predic_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

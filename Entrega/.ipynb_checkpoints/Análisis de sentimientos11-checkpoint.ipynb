{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimiento #\n",
    "### Juan Felipe Alfonso Avila ###\n",
    "### Felipe Diaz ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from smart_open import open\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo el dataset de tweets etiquetados con sentimiento. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetados = pd.read_csv(\"DataSet/tweets etiquetados.csv\")\n",
    "etiquetados = etiquetados.drop_duplicates(['user_name', 'text'], keep='first')\n",
    "etiquetados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo tweets de la clase ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID sentiment   user_name  \\\n",
       "0  570306133677760513   neutral     cairdin   \n",
       "1  570301130888122368  positive    jnardino   \n",
       "2  570301083672813571   neutral  yvonnalynn   \n",
       "3  570301031407624196  negative    jnardino   \n",
       "4  570300817074462722  negative    jnardino   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                  created at      place  \n",
       "0  2015-02-24 11:35:52 -0800        NaN  \n",
       "1  2015-02-24 11:15:59 -0800        NaN  \n",
       "2  2015-02-24 11:15:48 -0800  Lets Play  \n",
       "3  2015-02-24 11:15:36 -0800        NaN  \n",
       "4  2015-02-24 11:14:45 -0800        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clase = pd.read_csv(\"DataSet/Tweets.csv\")\n",
    "tweets_clase = tweets_clase.drop(['airline', 'negativereason_gold', 'airline_sentiment_gold', 'retweet_count', 'tweet_coord', 'user_timezone', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence'], axis=1)\n",
    "tweets_clase = tweets_clase.rename(columns={'tweet_id': 'ID', 'airline_sentiment': 'sentiment', 'name': 'user_name', 'tweet_created': 'created at', 'tweet_location': 'place'})\n",
    "tweets_clase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet = etiquetados.append(tweets_clase, ignore_index=True)\n",
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo IMBD, un dataset que nos ayudará a aumentar la data de entrenamiento. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A bad rip-off attempt on \"Seven\", complete wit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie was extremely poorly conceived from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We open with Colonel Luc Deveraux (Van Damme),...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*** May contain spoilers. ***   If LIVING ON T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***SPOILER ALERT***  I love Tim Roth, I really...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  A bad rip-off attempt on \"Seven\", complete wit...  negative\n",
       "1  This movie was extremely poorly conceived from...  negative\n",
       "2  We open with Colonel Luc Deveraux (Van Damme),...  negative\n",
       "3  *** May contain spoilers. ***   If LIVING ON T...  negative\n",
       "4  ***SPOILER ALERT***  I love Tim Roth, I really...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc = {'text': [], 'sentiment': []}\n",
    "neg_dir = ['DataSet/IMDB/train/neg/','DataSet/IMDB/test/neg/', 'DataSet/IMDB/train/pos/', 'DataSet/IMDB/test/neg/']\n",
    "for neg in neg_dir:\n",
    "    for file in listdir(neg):\n",
    "        for lines in open(neg+file):\n",
    "            dicc['text'].append(lines.replace('<br />', ' '))\n",
    "            if neg_dir[0].split('/')[-2] == 'neg':\n",
    "                dicc['sentiment'].append('negative')\n",
    "            else:\n",
    "                dicc['sentiment'].append('positive')\n",
    "IMDB = pd.DataFrame(dicc)\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet = DataSet.append(IMDB, ignore_index=True)\n",
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se hace la lectura de los diferentes lexicones ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiwordNet 3.0 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiWordNet[word] = {POS,\tID,\tPosScore,\tNegScore}\n",
    "contador = 0\n",
    "SentiWordNet = dict()\n",
    "for lines in open('Lexicones/SentiWordNet_3.0.0.txt'):\n",
    "    if lines.startswith('#'):\n",
    "        continue\n",
    "    line = lines.split('\\t')\n",
    "    palabra = line[4].split('#')[0]\n",
    "    if (palabra in SentiWordNet) or (palabra==''):\n",
    "        continue\n",
    "    else:\n",
    "        SentiWordNet[palabra]={'POS': line[0], 'ID': line[1], 'PosScore': line[2], 'NegScore': line[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFFIN 111 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFIN[word] = sentiment\n",
    "AFFIN = dict()\n",
    "for lines in open('Lexicones/AFINN-111.txt'):\n",
    "    AFFIN[lines.split('\\t')[0]]=(lines.split('\\t')[1]).split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### senticnet5 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senticnet['concept_name'] = ['pleasantness_value', 'attention_value', 'sensitivity_value', 'aptitude_value', 'primary_mood', 'secondary_mood', 'polarity_label', 'polarity_value', 'semantics1', 'semantics2', 'semantics3', 'semantics4', 'semantics5']\n",
    "from Lexicones.senticnet5 import senticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import re\n",
    "def process(text):\n",
    "    return re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de predicción ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def Gaussian(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    predictions = gnb.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def Trees(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    cart = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "    cart.fit(x_train, y_train)\n",
    "    predictions = cart.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    predictions = rfc.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con_stopwords = DataSet['text']\n",
    "data_sin_stopwords = [remove_stopwords(frase) for frase in  DataSet['text']]\n",
    "data_cs_sin_usr = [process(text) for text in data_con_stopwords] \n",
    "data_ss_con_usr = [process(text) for text in data_sin_stopwords]\n",
    "labels = DataSet['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hip 1. TFIDF normal #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases como aparecen en el dataset original ###\n",
    "No se han removido stopwords, ni usernames ni links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_con_stopwords).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_con_stopwords, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10426   459  1127]\n",
      " [   69   137   487]\n",
      " [   49    59   415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.21      0.20      0.20       693\n",
      "    positive       0.20      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.48     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8299062594496522\n",
      "Elapsed time: 3.5338685513 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11999     0    13]\n",
      " [  681     0    12]\n",
      " [  455     0    68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.73      0.13      0.22       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.55      0.38      0.39     13228\n",
      "weighted avg       0.86      0.91      0.88     13228\n",
      "\n",
      "accuracy:  0.9122316298760206\n",
      "Elapsed time: 11.1408371925 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11903    96    13]\n",
      " [  389   270    34]\n",
      " [  240    83   200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.60      0.39      0.47       693\n",
      "    positive       0.81      0.38      0.52       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.79      0.59      0.65     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9353643785908679\n",
      "Elapsed time: 134.0401480198 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con username y links pero sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_sin_stopwords = vectorizer.fit_transform(data_sin_stopwords).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_sin_stopwords, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10440   457  1115]\n",
      " [   69   144   480]\n",
      " [   53    54   416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.22      0.21      0.21       693\n",
      "    positive       0.21      0.80      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8315693982461445\n",
      "Elapsed time: 8.5375006199 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12009     3     0]\n",
      " [  689     4     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.57      0.01      0.01       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.49      0.34      0.32     13228\n",
      "weighted avg       0.85      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9081493801028122\n",
      "Elapsed time: 10.0792694092 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11804   171    37]\n",
      " [  348   293    52]\n",
      " [  179   115   229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.98      0.97     12012\n",
      "     neutral       0.51      0.42      0.46       693\n",
      "    positive       0.72      0.44      0.54       523\n",
      "\n",
      "    accuracy                           0.93     13228\n",
      "   macro avg       0.73      0.61      0.66     13228\n",
      "weighted avg       0.92      0.93      0.93     13228\n",
      "\n",
      "accuracy:  0.9318113093438162\n",
      "Elapsed time: 185.2910895348 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_cs_sin_usr = vectorizer.fit_transform(data_cs_sin_usr).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_cs_sin_usr, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10430   461  1121]\n",
      " [   70   139   484]\n",
      " [   49    60   414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.21      0.20      0.21       693\n",
      "    positive       0.21      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 3.1834657192 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11999     0    13]\n",
      " [  681     0    12]\n",
      " [  455     0    68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.73      0.13      0.22       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.55      0.38      0.39     13228\n",
      "weighted avg       0.86      0.91      0.88     13228\n",
      "\n",
      "accuracy:  0.9122316298760206\n",
      "Elapsed time: 11.1477282047 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11913    80    19]\n",
      " [  394   268    31]\n",
      " [  247    63   213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.65      0.39      0.49       693\n",
      "    positive       0.81      0.41      0.54       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.80      0.60      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9369519201693378\n",
      "Elapsed time: 140.1784198284 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_ss_con_usr = vectorizer.fit_transform(data_ss_con_usr).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_ss_con_usr, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10442   467  1103]\n",
      " [   69   147   477]\n",
      " [   54    57   412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.22      0.21      0.22       693\n",
      "    positive       0.21      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8316449954641669\n",
      "Elapsed time: 3.2018442154 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 8.7934968472 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11814   147    51]\n",
      " [  331   309    53]\n",
      " [  190    79   254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.98      0.97     12012\n",
      "     neutral       0.58      0.45      0.50       693\n",
      "    positive       0.71      0.49      0.58       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.75      0.64      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9356667674629574\n",
      "Elapsed time: 213.5082252026 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hip 2. TFIDF extendido con lexicones #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases como el dataset original ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.125, 0.875, 4.0, 1.2420000000000002]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "def Expansion(data):\n",
    "    expand = []\n",
    "    for frase in data:\n",
    "        splited = tknzr.tokenize(frase)\n",
    "        sum_swn_neg = 0\n",
    "        sum_swn_pos = 0\n",
    "        affin = 0\n",
    "        stnet = 0\n",
    "        word_stat = 0\n",
    "        for word in splited:\n",
    "            if word in SentiWordNet.keys():\n",
    "                sum_swn_neg += float(SentiWordNet[word]['NegScore'])\n",
    "                sum_swn_pos += float(SentiWordNet[word]['PosScore'])\n",
    "            if word in AFFIN.keys():\n",
    "                affin += float(AFFIN[word])\n",
    "            if word in senticnet.keys():\n",
    "                stnet += float(senticnet[word][7])\n",
    "        expand.append([sum_swn_neg, sum_swn_pos, affin, stnet])\n",
    "    return expand\n",
    "Expansion([\"hi, how are you, hope you are fine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extension(matriz, data):\n",
    "    expansion = np.array(Expansion(data))\n",
    "    return np.append(matriz, expansion, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normal, con stopwords, username y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_con_stopwords).toarray()\n",
    "re_data = extension(features_con_stopwords, data_con_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10448   606   958]\n",
      " [   75   213   405]\n",
      " [   51    87   385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.31      0.27       693\n",
      "    positive       0.22      0.74      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8350468702751739\n",
      "Elapsed time: 21.9205861092 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 11.2228467464 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11894    92    26]\n",
      " [  368   286    39]\n",
      " [  215    86   222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.62      0.41      0.49       693\n",
      "    positive       0.77      0.42      0.55       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.78      0.61      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9375566979135168\n",
      "Elapsed time: 128.9203782082 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_sin_stopwords).toarray()\n",
    "re_data = extension(features_con_stopwords, data_sin_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10452   574   986]\n",
      " [   75   201   417]\n",
      " [   54    76   393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.29      0.26       693\n",
      "    positive       0.22      0.75      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8350468702751739\n",
      "Elapsed time: 8.6804039478 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 10.1738352776 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11850   120    42]\n",
      " [  353   292    48]\n",
      " [  183    99   241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97     12012\n",
      "     neutral       0.57      0.42      0.49       693\n",
      "    positive       0.73      0.46      0.56       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.75      0.62      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9361203507710916\n",
      "Elapsed time: 160.3997936249 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### con stopwords, sin username, sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_cs_sin_usr).toarray()\n",
    "re_data = extension(features_con_stopwords, data_cs_sin_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10455   611   946]\n",
      " [   76   224   393]\n",
      " [   51    93   379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.32      0.28       693\n",
      "    positive       0.22      0.72      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8359540368914424\n",
      "Elapsed time: 15.7210333347 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 11.1051876545 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11907    87    18]\n",
      " [  371   286    36]\n",
      " [  223    70   230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.65      0.41      0.50       693\n",
      "    positive       0.81      0.44      0.57       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.80      0.61      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9391442394919867\n",
      "Elapsed time: 126.5031111240 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin stopwords, usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_ss_con_usr).toarray()\n",
    "re_data = extension(features_con_stopwords, data_ss_con_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10453   574   985]\n",
      " [   77   205   411]\n",
      " [   55    71   397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.30      0.27       693\n",
      "    positive       0.22      0.76      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8357272452373753\n",
      "Elapsed time: 8.2523317337 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 10.1110696793 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11857   109    46]\n",
      " [  359   284    50]\n",
      " [  199    75   249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97     12012\n",
      "     neutral       0.61      0.41      0.49       693\n",
      "    positive       0.72      0.48      0.57       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.76      0.62      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9366495312972483\n",
      "Elapsed time: 173.9221258163 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hip 3. Matriz de léxicones en vez de la matriz termino documento #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, usernames, links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_con_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10174  1517   321]\n",
      " [   10   598    85]\n",
      " [    9   303   211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.86      0.38       693\n",
      "    positive       0.34      0.40      0.37       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.53      0.70      0.56     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 0.4161374569 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 0.5316638947 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11595   264   153]\n",
      " [  359   244    90]\n",
      " [  212   122   189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96     12012\n",
      "     neutral       0.39      0.35      0.37       693\n",
      "    positive       0.44      0.36      0.40       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.56      0.57     13228\n",
      "weighted avg       0.90      0.91      0.91     13228\n",
      "\n",
      "accuracy:  0.9092833383731479\n",
      "Elapsed time: 8.3163254261 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_sin_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10178  1443   391]\n",
      " [   20   586    87]\n",
      " [   18   299   206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.85      0.39       693\n",
      "    positive       0.30      0.39      0.34       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.52      0.70      0.55     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8293014817054732\n",
      "Elapsed time: 0.3895101547 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 0.5335433483 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11560   323   129]\n",
      " [  356   271    66]\n",
      " [  238   129   156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.96     12012\n",
      "     neutral       0.37      0.39      0.38       693\n",
      "    positive       0.44      0.30      0.36       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.55      0.57     13228\n",
      "weighted avg       0.90      0.91      0.90     13228\n",
      "\n",
      "accuracy:  0.9061838524342304\n",
      "Elapsed time: 8.1373281479 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### con stopwords sin username y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_cs_sin_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10174  1517   321]\n",
      " [   10   598    85]\n",
      " [    9   303   211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.86      0.38       693\n",
      "    positive       0.34      0.40      0.37       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.53      0.70      0.56     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 0.4031682014 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 0.5304696560 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11598   258   156]\n",
      " [  360   243    90]\n",
      " [  209   122   192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96     12012\n",
      "     neutral       0.39      0.35      0.37       693\n",
      "    positive       0.44      0.37      0.40       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.56      0.58     13228\n",
      "weighted avg       0.90      0.91      0.91     13228\n",
      "\n",
      "accuracy:  0.9096613244632598\n",
      "Elapsed time: 8.3752281666 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sin stopwords, usernames, links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_ss_con_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10178  1445   389]\n",
      " [   20   586    87]\n",
      " [   18   299   206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.85      0.39       693\n",
      "    positive       0.30      0.39      0.34       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.52      0.70      0.55     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8293014817054732\n",
      "Elapsed time: 0.4006941319 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 0.5370659828 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11561   323   128]\n",
      " [  353   271    69]\n",
      " [  235   131   157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.96     12012\n",
      "     neutral       0.37      0.39      0.38       693\n",
      "    positive       0.44      0.30      0.36       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.55      0.57     13228\n",
      "weighted avg       0.90      0.91      0.90     13228\n",
      "\n",
      "accuracy:  0.9063350468702752\n",
      "Elapsed time: 8.6306686401 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hip 4. Módelo no supervisado ###\n",
    "Para el etiquetado no supervisado con los léxicones vamos a tomar la siguiente ecuación:<br>\n",
    "valor_sentimiento = SentiWordNet_pos - SentiWordNet_neg + AFFIN + senticnet <br>\n",
    "Donde:<br>\n",
    "valor_sentimiento>0 --> etiqueta positiva <br>\n",
    "valor_sentimiento==0 --> etiqueta neutral <br>\n",
    "valor_sentimiento<0 --> etiqueta negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.12276988206833989\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_con_stopwords):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords con usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.255851224674932\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_sin_stopwords):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.12276988206833989\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_cs_sin_usr):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords, sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.255851224674932\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_ss_con_usr):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomando el DataSet de los 10.000 tweets para asignarle las etiquetas ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones#\n",
    "Según la prueba de las hipótesis los mejores casos fueron:\n",
    "Naive Bayes en la hipótesis 3 usando frases sin stopwords pero con usernames y links, esta hipótesis arrojó un accuracy del 82.93% con un tiempo de ejecución de 0.3895 segundos.\n",
    "Decision Tree en la hipótesis 3 usando frases con stopwords, username y links arrojó un accuracy de 91.2% con un tiempo de ejecución de 0.5316 segundos; además, Random Forest también arrojó su mejor resultado en esta hipótesis obteniendo un accuracy de 90.92% con un tiempo de ejecución de 8.3263 segundos.\n",
    "Como se puede ver en los datos recolectados los 3 métodos en la hipotesis 3 se desenvuelven muy bien, sin embargo Decision Tree es el que mejor lo hace por la rápidez de ejecución, es por esto que este será el método de etiquedado del dataset de 10.000 tweets, claro está que usando la hipotesis 3 con stopwords, links y usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24984515954349E+018</td>\n",
       "      <td>YES, of course the US has more cases than othe...</td>\n",
       "      <td>groovytrip</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24984515909059E+018</td>\n",
       "      <td>NY/NJ metro area compared to the others in the...</td>\n",
       "      <td>W7VOA</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24984515987502E+018</td>\n",
       "      <td>Batman the animated series quarantine review. ...</td>\n",
       "      <td>RavensBread</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1,24984516008048E+018</td>\n",
       "      <td>https://t.co/5lg15ZaUr4 covidfact</td>\n",
       "      <td>SandraL81472811</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,24984516021477E+018</td>\n",
       "      <td>@assiaa_joellaa Your presence speaks for itsel...</td>\n",
       "      <td>nusrattyy</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0  1,24984515954349E+018  YES, of course the US has more cases than othe...   \n",
       "1  1,24984515909059E+018  NY/NJ metro area compared to the others in the...   \n",
       "3  1,24984515987502E+018  Batman the animated series quarantine review. ...   \n",
       "5  1,24984516008048E+018                  https://t.co/5lg15ZaUr4 covidfact   \n",
       "6  1,24984516021477E+018  @assiaa_joellaa Your presence speaks for itsel...   \n",
       "\n",
       "       screen_name                      created_at lang        country  \n",
       "0       groovytrip  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "1            W7VOA  Mon Apr 13 23:41:21 +0000 2020   en  United States  \n",
       "3      RavensBread  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "5  SandraL81472811  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "6        nusrattyy  Mon Apr 13 23:41:21 +0000 2020   en  United States  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coronavirus = pd.read_csv(\"dataset.csv\")\n",
    "coronavirus = coronavirus.drop_duplicates(['text'], keep='first')\n",
    "coronavirus = coronavirus[coronavirus.lang!='es']\n",
    "coronavirus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_con_stopwords)\n",
    "features_to_predict = Expansion(coronavirus['text'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "predictions = gnb.predict(features_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24984515954349E+018</td>\n",
       "      <td>YES, of course the US has more cases than othe...</td>\n",
       "      <td>groovytrip</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24984515909059E+018</td>\n",
       "      <td>NY/NJ metro area compared to the others in the...</td>\n",
       "      <td>W7VOA</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24984515987502E+018</td>\n",
       "      <td>Batman the animated series quarantine review. ...</td>\n",
       "      <td>RavensBread</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1,24984516008048E+018</td>\n",
       "      <td>https://t.co/5lg15ZaUr4 covidfact</td>\n",
       "      <td>SandraL81472811</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,24984516021477E+018</td>\n",
       "      <td>@assiaa_joellaa Your presence speaks for itsel...</td>\n",
       "      <td>nusrattyy</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0  1,24984515954349E+018  YES, of course the US has more cases than othe...   \n",
       "1  1,24984515909059E+018  NY/NJ metro area compared to the others in the...   \n",
       "3  1,24984515987502E+018  Batman the animated series quarantine review. ...   \n",
       "5  1,24984516008048E+018                  https://t.co/5lg15ZaUr4 covidfact   \n",
       "6  1,24984516021477E+018  @assiaa_joellaa Your presence speaks for itsel...   \n",
       "\n",
       "       screen_name                      created_at lang        country  \\\n",
       "0       groovytrip  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "1            W7VOA  Mon Apr 13 23:41:21 +0000 2020   en  United States   \n",
       "3      RavensBread  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "5  SandraL81472811  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "6        nusrattyy  Mon Apr 13 23:41:21 +0000 2020   en  United States   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1   neutral  \n",
       "3   neutral  \n",
       "5   neutral  \n",
       "6   neutral  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coronavirus['sentiment']=predictions\n",
    "coronavirus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creyendo en el análisis hecho anteriormente sobre las hipótesis se pasa a predecir el sentimiento de los 10.000 tweets, sin embargo estos no se pueden probar dado que no hay etiquetas de comparación.\n",
    "Por último se agrega en el csv para poder guardarlo, si así desea, en un .csv para tener la data de manera externa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

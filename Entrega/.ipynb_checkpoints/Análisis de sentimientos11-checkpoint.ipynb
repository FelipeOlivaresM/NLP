{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de sentimiento #\n",
    "### Juan Felipe Alfonso Avila ###\n",
    "### Felipe Diaz ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from smart_open import open\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo el dataset de tweets etiquetados con sentimiento. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetados = pd.read_csv(\"DataSet/tweets etiquetados.csv\")\n",
    "etiquetados = etiquetados.drop_duplicates(['user_name', 'text'], keep='first')\n",
    "etiquetados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo tweets de la clase ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID sentiment   user_name  \\\n",
       "0  570306133677760513   neutral     cairdin   \n",
       "1  570301130888122368  positive    jnardino   \n",
       "2  570301083672813571   neutral  yvonnalynn   \n",
       "3  570301031407624196  negative    jnardino   \n",
       "4  570300817074462722  negative    jnardino   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                  created at      place  \n",
       "0  2015-02-24 11:35:52 -0800        NaN  \n",
       "1  2015-02-24 11:15:59 -0800        NaN  \n",
       "2  2015-02-24 11:15:48 -0800  Lets Play  \n",
       "3  2015-02-24 11:15:36 -0800        NaN  \n",
       "4  2015-02-24 11:14:45 -0800        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clase = pd.read_csv(\"DataSet/Tweets.csv\")\n",
    "tweets_clase = tweets_clase.drop(['airline', 'negativereason_gold', 'airline_sentiment_gold', 'retweet_count', 'tweet_coord', 'user_timezone', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence'], axis=1)\n",
    "tweets_clase = tweets_clase.rename(columns={'tweet_id': 'ID', 'airline_sentiment': 'sentiment', 'name': 'user_name', 'tweet_created': 'created at', 'tweet_location': 'place'})\n",
    "tweets_clase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet = etiquetados.append(tweets_clase, ignore_index=True)\n",
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo IMBD, un dataset que nos ayudar√° a aumentar la data de entrenamiento. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A bad rip-off attempt on \"Seven\", complete wit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie was extremely poorly conceived from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We open with Colonel Luc Deveraux (Van Damme),...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*** May contain spoilers. ***   If LIVING ON T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***SPOILER ALERT***  I love Tim Roth, I really...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  A bad rip-off attempt on \"Seven\", complete wit...  negative\n",
       "1  This movie was extremely poorly conceived from...  negative\n",
       "2  We open with Colonel Luc Deveraux (Van Damme),...  negative\n",
       "3  *** May contain spoilers. ***   If LIVING ON T...  negative\n",
       "4  ***SPOILER ALERT***  I love Tim Roth, I really...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc = {'text': [], 'sentiment': []}\n",
    "neg_dir = ['DataSet/IMDB/train/neg/','DataSet/IMDB/test/neg/', 'DataSet/IMDB/train/pos/', 'DataSet/IMDB/test/neg/']\n",
    "for neg in neg_dir:\n",
    "    for file in listdir(neg):\n",
    "        for lines in open(neg+file):\n",
    "            dicc['text'].append(lines.replace('<br />', ' '))\n",
    "            if neg_dir[0].split('/')[-2] == 'neg':\n",
    "                dicc['sentiment'].append('negative')\n",
    "            else:\n",
    "                dicc['sentiment'].append('positive')\n",
    "IMDB = pd.DataFrame(dicc)\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>created at</th>\n",
       "      <th>place</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24761620732016E+018</td>\n",
       "      <td>dgtlchrch</td>\n",
       "      <td>SCRIPTURE MAKES SENSE NOW - This is the second...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24761620801222E+018</td>\n",
       "      <td>DanWuori</td>\n",
       "      <td>\"The financial realities for #childcare busine...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,24761620810456E+018</td>\n",
       "      <td>chaunceydevega</td>\n",
       "      <td>Mind control expert Steven Hassan explains the...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24761620883858E+018</td>\n",
       "      <td>ZaynabKAhmed</td>\n",
       "      <td>I miss the feminist makeup group chat, I wonde...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,24761620874209E+018</td>\n",
       "      <td>minsterfm</td>\n",
       "      <td>NATIONAL NEWS: Coronavirus: What do the figure...</td>\n",
       "      <td>2020-04-07 20:04:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user_name  \\\n",
       "0  1,24761620732016E+018       dgtlchrch   \n",
       "1  1,24761620801222E+018        DanWuori   \n",
       "2  1,24761620810456E+018  chaunceydevega   \n",
       "3  1,24761620883858E+018    ZaynabKAhmed   \n",
       "4  1,24761620874209E+018       minsterfm   \n",
       "\n",
       "                                                text           created at  \\\n",
       "0  SCRIPTURE MAKES SENSE NOW - This is the second...  2020-04-07 20:04:18   \n",
       "1  \"The financial realities for #childcare busine...  2020-04-07 20:04:18   \n",
       "2  Mind control expert Steven Hassan explains the...  2020-04-07 20:04:18   \n",
       "3  I miss the feminist makeup group chat, I wonde...  2020-04-07 20:04:18   \n",
       "4  NATIONAL NEWS: Coronavirus: What do the figure...  2020-04-07 20:04:18   \n",
       "\n",
       "  place sentiment  \n",
       "0   NaN   neutral  \n",
       "1   NaN   neutral  \n",
       "2   NaN  negative  \n",
       "3   NaN   neutral  \n",
       "4   NaN   neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet = DataSet.append(IMDB, ignore_index=True)\n",
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se hace la lectura de los diferentes lexicones ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiwordNet 3.0 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiWordNet[word] = {POS,\tID,\tPosScore,\tNegScore}\n",
    "contador = 0\n",
    "SentiWordNet = dict()\n",
    "for lines in open('Lexicones/SentiWordNet_3.0.0.txt'):\n",
    "    if lines.startswith('#'):\n",
    "        continue\n",
    "    line = lines.split('\\t')\n",
    "    palabra = line[4].split('#')[0]\n",
    "    if (palabra in SentiWordNet) or (palabra==''):\n",
    "        continue\n",
    "    else:\n",
    "        SentiWordNet[palabra]={'POS': line[0], 'ID': line[1], 'PosScore': line[2], 'NegScore': line[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFFIN 111 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFIN[word] = sentiment\n",
    "AFFIN = dict()\n",
    "for lines in open('Lexicones/AFINN-111.txt'):\n",
    "    AFFIN[lines.split('\\t')[0]]=(lines.split('\\t')[1]).split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### senticnet5 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senticnet['concept_name'] = ['pleasantness_value', 'attention_value', 'sensitivity_value', 'aptitude_value', 'primary_mood', 'secondary_mood', 'polarity_label', 'polarity_value', 'semantics1', 'semantics2', 'semantics3', 'semantics4', 'semantics5']\n",
    "from Lexicones.senticnet5 import senticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import re\n",
    "def process(text):\n",
    "    return re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todos de predicci√≥n ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def Gaussian(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    predictions = gnb.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def Trees(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    cart = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "    cart.fit(x_train, y_train)\n",
    "    predictions = cart.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(x_train, y_train, x_test, y_test):\n",
    "    start_time = time()\n",
    "    rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    predictions = rfc.predict(x_test)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print(\"accuracy: \",accuracy_score(y_test, predictions))\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con_stopwords = DataSet['text']\n",
    "data_sin_stopwords = [remove_stopwords(frase) for frase in  DataSet['text']]\n",
    "data_cs_sin_usr = [process(text) for text in data_con_stopwords] \n",
    "data_ss_con_usr = [process(text) for text in data_sin_stopwords]\n",
    "labels = DataSet['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hip 1. TFIDF normal #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases como aparecen en el dataset original ###\n",
    "No se han removido stopwords, ni usernames ni links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_con_stopwords).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_con_stopwords, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10426   459  1127]\n",
      " [   69   137   487]\n",
      " [   49    59   415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.21      0.20      0.20       693\n",
      "    positive       0.20      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.48     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8299062594496522\n",
      "Elapsed time: 3.5338685513 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11999     0    13]\n",
      " [  681     0    12]\n",
      " [  455     0    68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.73      0.13      0.22       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.55      0.38      0.39     13228\n",
      "weighted avg       0.86      0.91      0.88     13228\n",
      "\n",
      "accuracy:  0.9122316298760206\n",
      "Elapsed time: 11.1408371925 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11903    96    13]\n",
      " [  389   270    34]\n",
      " [  240    83   200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.60      0.39      0.47       693\n",
      "    positive       0.81      0.38      0.52       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.79      0.59      0.65     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9353643785908679\n",
      "Elapsed time: 134.0401480198 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con username y links pero sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_sin_stopwords = vectorizer.fit_transform(data_sin_stopwords).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_sin_stopwords, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10440   457  1115]\n",
      " [   69   144   480]\n",
      " [   53    54   416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.22      0.21      0.21       693\n",
      "    positive       0.21      0.80      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8315693982461445\n",
      "Elapsed time: 8.5375006199 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12009     3     0]\n",
      " [  689     4     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.57      0.01      0.01       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.49      0.34      0.32     13228\n",
      "weighted avg       0.85      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9081493801028122\n",
      "Elapsed time: 10.0792694092 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11804   171    37]\n",
      " [  348   293    52]\n",
      " [  179   115   229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.98      0.97     12012\n",
      "     neutral       0.51      0.42      0.46       693\n",
      "    positive       0.72      0.44      0.54       523\n",
      "\n",
      "    accuracy                           0.93     13228\n",
      "   macro avg       0.73      0.61      0.66     13228\n",
      "weighted avg       0.92      0.93      0.93     13228\n",
      "\n",
      "accuracy:  0.9318113093438162\n",
      "Elapsed time: 185.2910895348 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_cs_sin_usr = vectorizer.fit_transform(data_cs_sin_usr).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_cs_sin_usr, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10430   461  1121]\n",
      " [   70   139   484]\n",
      " [   49    60   414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.92     12012\n",
      "     neutral       0.21      0.20      0.21       693\n",
      "    positive       0.21      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 3.1834657192 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11999     0    13]\n",
      " [  681     0    12]\n",
      " [  455     0    68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.73      0.13      0.22       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.55      0.38      0.39     13228\n",
      "weighted avg       0.86      0.91      0.88     13228\n",
      "\n",
      "accuracy:  0.9122316298760206\n",
      "Elapsed time: 11.1477282047 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11913    80    19]\n",
      " [  394   268    31]\n",
      " [  247    63   213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.65      0.39      0.49       693\n",
      "    positive       0.81      0.41      0.54       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.80      0.60      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9369519201693378\n",
      "Elapsed time: 140.1784198284 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_ss_con_usr = vectorizer.fit_transform(data_ss_con_usr).toarray()\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_ss_con_usr, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10442   467  1103]\n",
      " [   69   147   477]\n",
      " [   54    57   412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.22      0.21      0.22       693\n",
      "    positive       0.21      0.79      0.33       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.47      0.62      0.49     13228\n",
      "weighted avg       0.92      0.83      0.86     13228\n",
      "\n",
      "accuracy:  0.8316449954641669\n",
      "Elapsed time: 3.2018442154 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 8.7934968472 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11814   147    51]\n",
      " [  331   309    53]\n",
      " [  190    79   254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.98      0.97     12012\n",
      "     neutral       0.58      0.45      0.50       693\n",
      "    positive       0.71      0.49      0.58       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.75      0.64      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9356667674629574\n",
      "Elapsed time: 213.5082252026 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hip 2. TFIDF extendido con lexicones #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases como el dataset original ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.125, 0.875, 4.0, 1.2420000000000002]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "def Expansion(data):\n",
    "    expand = []\n",
    "    for frase in data:\n",
    "        splited = tknzr.tokenize(frase)\n",
    "        sum_swn_neg = 0\n",
    "        sum_swn_pos = 0\n",
    "        affin = 0\n",
    "        stnet = 0\n",
    "        word_stat = 0\n",
    "        for word in splited:\n",
    "            if word in SentiWordNet.keys():\n",
    "                sum_swn_neg += float(SentiWordNet[word]['NegScore'])\n",
    "                sum_swn_pos += float(SentiWordNet[word]['PosScore'])\n",
    "            if word in AFFIN.keys():\n",
    "                affin += float(AFFIN[word])\n",
    "            if word in senticnet.keys():\n",
    "                stnet += float(senticnet[word][7])\n",
    "        expand.append([sum_swn_neg, sum_swn_pos, affin, stnet])\n",
    "    return expand\n",
    "Expansion([\"hi, how are you, hope you are fine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extension(matriz, data):\n",
    "    expansion = np.array(Expansion(data))\n",
    "    return np.append(matriz, expansion, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normal, con stopwords, username y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_con_stopwords).toarray()\n",
    "re_data = extension(features_con_stopwords, data_con_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10448   606   958]\n",
      " [   75   213   405]\n",
      " [   51    87   385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.31      0.27       693\n",
      "    positive       0.22      0.74      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8350468702751739\n",
      "Elapsed time: 21.9205861092 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 11.2228467464 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11894    92    26]\n",
      " [  368   286    39]\n",
      " [  215    86   222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.62      0.41      0.49       693\n",
      "    positive       0.77      0.42      0.55       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.78      0.61      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9375566979135168\n",
      "Elapsed time: 128.9203782082 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_sin_stopwords).toarray()\n",
    "re_data = extension(features_con_stopwords, data_sin_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10452   574   986]\n",
      " [   75   201   417]\n",
      " [   54    76   393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.29      0.26       693\n",
      "    positive       0.22      0.75      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8350468702751739\n",
      "Elapsed time: 8.6804039478 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 10.1738352776 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11850   120    42]\n",
      " [  353   292    48]\n",
      " [  183    99   241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97     12012\n",
      "     neutral       0.57      0.42      0.49       693\n",
      "    positive       0.73      0.46      0.56       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.75      0.62      0.67     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9361203507710916\n",
      "Elapsed time: 160.3997936249 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### con stopwords, sin username, sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_cs_sin_usr).toarray()\n",
    "re_data = extension(features_con_stopwords, data_cs_sin_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10455   611   946]\n",
      " [   76   224   393]\n",
      " [   51    93   379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.32      0.28       693\n",
      "    positive       0.22      0.72      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8359540368914424\n",
      "Elapsed time: 15.7210333347 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 11.1051876545 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11907    87    18]\n",
      " [  371   286    36]\n",
      " [  223    70   230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97     12012\n",
      "     neutral       0.65      0.41      0.50       693\n",
      "    positive       0.81      0.44      0.57       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.80      0.61      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9391442394919867\n",
      "Elapsed time: 126.5031111240 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin stopwords, usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000, min_df=7, max_df=0.8)\n",
    "features_con_stopwords = vectorizer.fit_transform(data_ss_con_usr).toarray()\n",
    "re_data = extension(features_con_stopwords, data_ss_con_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10453   574   985]\n",
      " [   77   205   411]\n",
      " [   55    71   397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.87      0.93     12012\n",
      "     neutral       0.24      0.30      0.27       693\n",
      "    positive       0.22      0.76      0.34       523\n",
      "\n",
      "    accuracy                           0.84     13228\n",
      "   macro avg       0.48      0.64      0.51     13228\n",
      "weighted avg       0.92      0.84      0.87     13228\n",
      "\n",
      "accuracy:  0.8357272452373753\n",
      "Elapsed time: 8.2523317337 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 10.1110696793 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11857   109    46]\n",
      " [  359   284    50]\n",
      " [  199    75   249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97     12012\n",
      "     neutral       0.61      0.41      0.49       693\n",
      "    positive       0.72      0.48      0.57       523\n",
      "\n",
      "    accuracy                           0.94     13228\n",
      "   macro avg       0.76      0.62      0.68     13228\n",
      "weighted avg       0.93      0.94      0.93     13228\n",
      "\n",
      "accuracy:  0.9366495312972483\n",
      "Elapsed time: 173.9221258163 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hip 3. Matriz de l√©xicones en vez de la matriz termino documento #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, usernames, links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_con_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10174  1517   321]\n",
      " [   10   598    85]\n",
      " [    9   303   211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.86      0.38       693\n",
      "    positive       0.34      0.40      0.37       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.53      0.70      0.56     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 0.4161374569 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 0.5316638947 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11595   264   153]\n",
      " [  359   244    90]\n",
      " [  212   122   189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96     12012\n",
      "     neutral       0.39      0.35      0.37       693\n",
      "    positive       0.44      0.36      0.40       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.56      0.57     13228\n",
      "weighted avg       0.90      0.91      0.91     13228\n",
      "\n",
      "accuracy:  0.9092833383731479\n",
      "Elapsed time: 8.3163254261 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_sin_stopwords)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10178  1443   391]\n",
      " [   20   586    87]\n",
      " [   18   299   206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.85      0.39       693\n",
      "    positive       0.30      0.39      0.34       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.52      0.70      0.55     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8293014817054732\n",
      "Elapsed time: 0.3895101547 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 0.5335433483 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11560   323   129]\n",
      " [  356   271    66]\n",
      " [  238   129   156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.96     12012\n",
      "     neutral       0.37      0.39      0.38       693\n",
      "    positive       0.44      0.30      0.36       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.55      0.57     13228\n",
      "weighted avg       0.90      0.91      0.90     13228\n",
      "\n",
      "accuracy:  0.9061838524342304\n",
      "Elapsed time: 8.1373281479 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### con stopwords sin username y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_cs_sin_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10174  1517   321]\n",
      " [   10   598    85]\n",
      " [    9   303   211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.86      0.38       693\n",
      "    positive       0.34      0.40      0.37       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.53      0.70      0.56     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8302842455397641\n",
      "Elapsed time: 0.4031682014 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11843     0   169]\n",
      " [  614     0    79]\n",
      " [  300     0   223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.47      0.43      0.45       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.47      0.47      0.47     13228\n",
      "weighted avg       0.86      0.91      0.89     13228\n",
      "\n",
      "accuracy:  0.9121560326579982\n",
      "Elapsed time: 0.5304696560 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11598   258   156]\n",
      " [  360   243    90]\n",
      " [  209   122   192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96     12012\n",
      "     neutral       0.39      0.35      0.37       693\n",
      "    positive       0.44      0.37      0.40       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.56      0.58     13228\n",
      "weighted avg       0.90      0.91      0.91     13228\n",
      "\n",
      "accuracy:  0.9096613244632598\n",
      "Elapsed time: 8.3752281666 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sin stopwords, usernames, links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_ss_con_usr)\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10178  1445   389]\n",
      " [   20   586    87]\n",
      " [   18   299   206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     12012\n",
      "     neutral       0.25      0.85      0.39       693\n",
      "    positive       0.30      0.39      0.34       523\n",
      "\n",
      "    accuracy                           0.83     13228\n",
      "   macro avg       0.52      0.70      0.55     13228\n",
      "weighted avg       0.93      0.83      0.87     13228\n",
      "\n",
      "accuracy:  0.8293014817054732\n",
      "Elapsed time: 0.4006941319 seconds.\n"
     ]
    }
   ],
   "source": [
    "Gaussian(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12012     0     0]\n",
      " [  693     0     0]\n",
      " [  523     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Documentos/EntornosPython/proyecto_final/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      1.00      0.95     12012\n",
      "     neutral       0.00      0.00      0.00       693\n",
      "    positive       0.00      0.00      0.00       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.30      0.33      0.32     13228\n",
      "weighted avg       0.82      0.91      0.86     13228\n",
      "\n",
      "accuracy:  0.9080737828847898\n",
      "Elapsed time: 0.5370659828 seconds.\n"
     ]
    }
   ],
   "source": [
    "Trees(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11561   323   128]\n",
      " [  353   271    69]\n",
      " [  235   131   157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.96     12012\n",
      "     neutral       0.37      0.39      0.38       693\n",
      "    positive       0.44      0.30      0.36       523\n",
      "\n",
      "    accuracy                           0.91     13228\n",
      "   macro avg       0.59      0.55      0.57     13228\n",
      "weighted avg       0.90      0.91      0.90     13228\n",
      "\n",
      "accuracy:  0.9063350468702752\n",
      "Elapsed time: 8.6306686401 seconds.\n"
     ]
    }
   ],
   "source": [
    "RandomForest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hip 4. M√≥delo no supervisado ###\n",
    "Para el etiquetado no supervisado con los l√©xicones vamos a tomar la siguiente ecuaci√≥n:<br>\n",
    "valor_sentimiento = SentiWordNet_pos - SentiWordNet_neg + AFFIN + senticnet <br>\n",
    "Donde:<br>\n",
    "valor_sentimiento>0 --> etiqueta positiva <br>\n",
    "valor_sentimiento==0 --> etiqueta neutral <br>\n",
    "valor_sentimiento<0 --> etiqueta negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.12276988206833989\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_con_stopwords):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords con usernames y links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.255851224674932\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_sin_stopwords):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases con stopwords, sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.12276988206833989\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_cs_sin_usr):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frases sin stopwords, sin usernames y sin links ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.255851224674932\n"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "for frase in Expansion(data_ss_con_usr):\n",
    "    valor_sentimiento = frase[1]-frase[0]+frase[2]+frase[3]\n",
    "    if valor_sentimiento>0:\n",
    "        predicciones.append('positive')\n",
    "    elif valor_sentimiento==0:\n",
    "        predicciones.append('neutral')\n",
    "    elif valor_sentimiento<0:\n",
    "        predicciones.append('negative')\n",
    "print(\"accuracy: \",accuracy_score(labels, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomando el DataSet de los 10.000 tweets para asignarle las etiquetas ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones#\n",
    "Seg√∫n la prueba de las hip√≥tesis los mejores casos fueron:\n",
    "Naive Bayes en la hip√≥tesis 3 usando frases sin stopwords pero con usernames y links, esta hip√≥tesis arroj√≥ un accuracy del 82.93% con un tiempo de ejecuci√≥n de 0.3895 segundos.\n",
    "Decision Tree en la hip√≥tesis 3 usando frases con stopwords, username y links arroj√≥ un accuracy de 91.2% con un tiempo de ejecuci√≥n de 0.5316 segundos; adem√°s, Random Forest tambi√©n arroj√≥ su mejor resultado en esta hip√≥tesis obteniendo un accuracy de 90.92% con un tiempo de ejecuci√≥n de 8.3263 segundos.\n",
    "Como se puede ver en los datos recolectados los 3 m√©todos en la hipotesis 3 se desenvuelven muy bien, sin embargo Decision Tree es el que mejor lo hace por la r√°pidez de ejecuci√≥n, es por esto que este ser√° el m√©todo de etiquedado del dataset de 10.000 tweets, claro est√° que usando la hipotesis 3 con stopwords, links y usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24984515954349E+018</td>\n",
       "      <td>YES, of course the US has more cases than othe...</td>\n",
       "      <td>groovytrip</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24984515909059E+018</td>\n",
       "      <td>NY/NJ metro area compared to the others in the...</td>\n",
       "      <td>W7VOA</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24984515987502E+018</td>\n",
       "      <td>Batman the animated series quarantine review. ...</td>\n",
       "      <td>RavensBread</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1,24984516008048E+018</td>\n",
       "      <td>https://t.co/5lg15ZaUr4 covidfact</td>\n",
       "      <td>SandraL81472811</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,24984516021477E+018</td>\n",
       "      <td>@assiaa_joellaa Your presence speaks for itsel...</td>\n",
       "      <td>nusrattyy</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0  1,24984515954349E+018  YES, of course the US has more cases than othe...   \n",
       "1  1,24984515909059E+018  NY/NJ metro area compared to the others in the...   \n",
       "3  1,24984515987502E+018  Batman the animated series quarantine review. ...   \n",
       "5  1,24984516008048E+018                  https://t.co/5lg15ZaUr4 covidfact   \n",
       "6  1,24984516021477E+018  @assiaa_joellaa Your presence speaks for itsel...   \n",
       "\n",
       "       screen_name                      created_at lang        country  \n",
       "0       groovytrip  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "1            W7VOA  Mon Apr 13 23:41:21 +0000 2020   en  United States  \n",
       "3      RavensBread  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "5  SandraL81472811  Mon Apr 13 23:41:21 +0000 2020   en            NaN  \n",
       "6        nusrattyy  Mon Apr 13 23:41:21 +0000 2020   en  United States  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coronavirus = pd.read_csv(\"dataset.csv\")\n",
    "coronavirus = coronavirus.drop_duplicates(['text'], keep='first')\n",
    "coronavirus = coronavirus[coronavirus.lang!='es']\n",
    "coronavirus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data = Expansion(data_con_stopwords)\n",
    "features_to_predict = Expansion(coronavirus['text'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(re_data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "predictions = gnb.predict(features_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,24984515954349E+018</td>\n",
       "      <td>YES, of course the US has more cases than othe...</td>\n",
       "      <td>groovytrip</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,24984515909059E+018</td>\n",
       "      <td>NY/NJ metro area compared to the others in the...</td>\n",
       "      <td>W7VOA</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,24984515987502E+018</td>\n",
       "      <td>Batman the animated series quarantine review. ...</td>\n",
       "      <td>RavensBread</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1,24984516008048E+018</td>\n",
       "      <td>https://t.co/5lg15ZaUr4 covidfact</td>\n",
       "      <td>SandraL81472811</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,24984516021477E+018</td>\n",
       "      <td>@assiaa_joellaa Your presence speaks for itsel...</td>\n",
       "      <td>nusrattyy</td>\n",
       "      <td>Mon Apr 13 23:41:21 +0000 2020</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0  1,24984515954349E+018  YES, of course the US has more cases than othe...   \n",
       "1  1,24984515909059E+018  NY/NJ metro area compared to the others in the...   \n",
       "3  1,24984515987502E+018  Batman the animated series quarantine review. ...   \n",
       "5  1,24984516008048E+018                  https://t.co/5lg15ZaUr4 covidfact   \n",
       "6  1,24984516021477E+018  @assiaa_joellaa Your presence speaks for itsel...   \n",
       "\n",
       "       screen_name                      created_at lang        country  \\\n",
       "0       groovytrip  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "1            W7VOA  Mon Apr 13 23:41:21 +0000 2020   en  United States   \n",
       "3      RavensBread  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "5  SandraL81472811  Mon Apr 13 23:41:21 +0000 2020   en            NaN   \n",
       "6        nusrattyy  Mon Apr 13 23:41:21 +0000 2020   en  United States   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1   neutral  \n",
       "3   neutral  \n",
       "5   neutral  \n",
       "6   neutral  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coronavirus['sentiment']=predictions\n",
    "coronavirus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creyendo en el an√°lisis hecho anteriormente sobre las hip√≥tesis se pasa a predecir el sentimiento de los 10.000 tweets, sin embargo estos no se pueden probar dado que no hay etiquetas de comparaci√≥n.\n",
    "Por √∫ltimo se agrega en el csv para poder guardarlo, si as√≠ desea, en un .csv para tener la data de manera externa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos supervisados para mourning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta primera sección del notebook corresponde con el método de cargar df, se usa para entrenar los diferentes modelos implícitamente ya que siempre que se entrena un modelo de luto se usa el mismo df, por lo que es indispensable para el proceso de entrenamiento, el método lo que hace es cargar de los diferentes archivos .csv reunidos por todos los grupos los datos tageados, los normaliza y dependiendo de los parámetros de entrada del método también los lematizar y los balancea, además de normalizar las etiquetas de mourning y no mourning como 1 para mourning y 0 para no mourning, en la parte de lematización es importante resaltar que se usan lematizadores diferentes para ingles y español.\n",
    "\n",
    "#### Carga de datos:\n",
    "Para la carga de datos el método lee la carpeta de datos para mourning, donde se encuentran enumerados los archivos .csv, dependiendo del número de archivo el método trata al archivo de una manera u otra, ya que los rangos de números corresponden con los diferentes equipos, siendo los datos de 1 y 2 de un equipo, 3 de otro y 4 de otro, por esto se tratan de formas distintas, en esta primera parte se cargan solo las columnas de texto, idioma y el tag de mourning, por lo que además se deben renombrar algunas columnas en ciertos archivos, luego de esto se eliminan las filas que tengan valores nulos en cualquier columna, se eliminan las duplicados usando la columna texto com indicador y se filtran los datos cargados de tal forma que solo pasen los datos que tienen como idiomas ingles o español y como tag 1 o 0, además se reinician los índices del df, posterior a esto usando expresiones regulares se eliminan los saltos de línea los espaciados de más de un espacio, los url, y los espacios al principio y fin de cada texto en el df, esto para normalizar los datos entregados.\n",
    "\n",
    "#### Lematizacion:\n",
    "La lematización, que es indicada por la segunda variable de entrada del método, la cual es binaria, se vale de la columna de idioma o lang para lematizar el texto usando un lematizador para ingles o español, para esto recorre todo el df identificando el idioma con la columna lang y lematizando el texto uno a uno según el lematizador correspondiente.\n",
    "\n",
    "#### Balanceamiento de datos:\n",
    "Por último para el balanceamiento de los datos se usa la primera variable del método, la cual también es binaria, para balancear el df de salida, para esto se crea una columna adicional en el df llamada sello, en sello se usan los atributos de idioma y de mourning en conjunto para crear una marca en el df según estos dos atributos, luego de completar los sellos se usan estos para que todos los sellos queden con la misma cantidad de datos en el df usando un muestreo aleatorio en df que fueron agrupados y separados del resto según su sello o marca, la cantidad de datos en cada muestra se determina usando la cantidad del df más pequeño resultante de la separación y agrupación por sellos, luego se unen de nuevo los df de muestras y se elimina la columna sellos, de esta forma la cantidad de datos de idioma y mourning se encuentran iguales en el df de salida en cada posible combinación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# balance_data: 0 para retornar dataframe sin balancear o 1 para retornar\n",
    "# dataframe balanceado.\n",
    "# lematizacion: lematiza los textos usando nltk 0 para no lematizar y 1\n",
    "# para retornar el texto lematizado.\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_mourning_df(balance_data, lematizacion):\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from sklearn.utils import resample\n",
    "    import os, re, sys, pandas\n",
    "\n",
    "    mourning_folder = './entrenamiento de modelos/datos mourning'\n",
    "    mourning_df = pandas.DataFrame(columns=['text', 'lang', 'mourning'])\n",
    "    path, subfolders, files_list = list(os.walk(mourning_folder))[0]\n",
    "    files_list.sort()\n",
    "\n",
    "    for i in range(len(files_list)):\n",
    "        sys.stdout.write(\"\\rPreparando df \" + str(round(((i + 1) / (len(files_list))) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        file_name, file_ext = files_list[i].split(\".\")\n",
    "\n",
    "        if file_ext == 'csv':\n",
    "            file_path = path + \"/\" + file_name + \".\" + file_ext\n",
    "            df = pandas.read_csv(file_path, encoding='utf8', dtype=str, engine='python')\n",
    "            numero_de_archivo = int(file_name.split(\"_\")[0])\n",
    "\n",
    "            if numero_de_archivo == 1 or numero_de_archivo == 2:\n",
    "                df = df.filter(['text', 'lang', 'mourning'])\n",
    "                df['mourning'] = df.mourning.map({'4': '0', '1': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "            if numero_de_archivo == 3:\n",
    "                df = df.filter(['text', 'lang', 'tag'])\n",
    "                df.columns = ['text', 'lang', 'mourning']\n",
    "                df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "            if numero_de_archivo == 4:\n",
    "                df = df.filter(['tweet', 'lang', 'mourning'])\n",
    "                df.columns = ['text', 'lang', 'mourning']\n",
    "                df['mourning'] = df.mourning.map({'no mourning': '0', 'mourning': '1'})\n",
    "                mourning_df = mourning_df.append(df)\n",
    "\n",
    "    del df\n",
    "    print(\"\")\n",
    "    mourning_df.dropna()\n",
    "    mourning_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    mourning_df = mourning_df.loc[mourning_df['mourning'].isin(['1', '0'])]\n",
    "    mourning_df = mourning_df.loc[mourning_df['lang'].isin(['es', 'en'])]\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for i, row in mourning_df.iterrows():\n",
    "        sys.stdout.write(\"\\rNormalizando df \" + str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2)) + \"%\")\n",
    "        sys.stdout.flush()\n",
    "        mourning_df.at[i, 'text'] = (\n",
    "            re.sub('\\s+', ' ',\n",
    "                   re.sub(' +', ' ',\n",
    "                          re.sub(\"http\\S+\", \"\",\n",
    "                                 re.sub(r'\\b(?=\\w*[j])[aeiouj]{2,}\\b', 'jajaja',\n",
    "                                        re.sub(r'[\\b@]\\w+\\s{1}', '', str(mourning_df.at[i, 'text'])\n",
    "                                               )))))).strip()\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    if balance_data == 1:\n",
    "        mourning_df[\"Sello\"] = 0\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rCreando sellos de balanceamiento \" +\n",
    "                str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2))\n",
    "                + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            mourning_df.at[i, 'sello'] = str(mourning_df.at[i, 'lang']) + '_' + str(mourning_df.at[i, 'mourning'])\n",
    "        print(\"\\nBalanceando df\")\n",
    "        min_len1 = int(min(mourning_df['sello'].value_counts()))\n",
    "        df_0 = resample(mourning_df[mourning_df.sello == 'es_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_1 = resample(mourning_df[mourning_df.sello == 'es_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_2 = resample(mourning_df[mourning_df.sello == 'en_0'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        df_3 = resample(mourning_df[mourning_df.sello == 'en_1'], replace=False, n_samples=min_len1, random_state=1)\n",
    "        mourning_df = pandas.concat([df_0, df_1, df_2, df_3])\n",
    "        mourning_df = mourning_df.filter(['text', 'lang', 'mourning'])\n",
    "\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if lematizacion == 1:\n",
    "        stemmer_en = SnowballStemmer('english')\n",
    "        stemmer_es = SnowballStemmer('spanish')\n",
    "        for i, row in mourning_df.iterrows():\n",
    "            sys.stdout.write(\n",
    "                \"\\rLematizando df \" + str(round(((i + 1) / (mourning_df.shape[0])) * 100, 2)) + \"%\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            if type(mourning_df.at[i, 'text']) is str and mourning_df.at[i, 'lang'] == 'es':\n",
    "                mourning_df.at[i, 'text'] = str(stemmer_es.stem(mourning_df.at[i, 'text'])).lower()\n",
    "            elif type(mourning_df.at[i, 'text']) is str and mourning_df.at[i, 'lang'] == 'en':\n",
    "                mourning_df.at[i, 'text'] = str(stemmer_en.stem(mourning_df.at[i, 'text'])).lower()\n",
    "        print(\"\")\n",
    "\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Df mourning entregado\\n\")\n",
    "    mourning_df.sort_values('text', inplace=True)\n",
    "    mourning_df.reset_index(drop=True, inplace=True)\n",
    "    return mourning_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda sección del notebook está el código necesario para entrenar los diferentes modelos supervisados de mourning dispuesto como método para ser implementado y usado fácilmente, este método se vale del de get_mourning_df, ya que este provee el df necesario para entrenar los diferentes modelos supervisados que se quieren entrenar.\n",
    "\n",
    "El pipeline seguido para entrenar los modelos de mourning se basa primero en seleccionar el modelo que se va a entrenar, este se selecciona con el primer parámetro del método, el cual es una cadena donde se escriben las iniciales del modelo: \n",
    "\n",
    "GBT: para gradient boosting trees.\n",
    "NN: para MPL o redes neuronales.\n",
    "DT: para árboles de decisión.\n",
    "RF: para random forest.\n",
    "NB: para naive bayes.\n",
    "\n",
    "Luego de seleccionar el modelo se carga el df haciendo uso del método get_mourning_df, los parámetros de este corresponden con los dos restantes del método de entrenamiento, luego de cargar el df este se divide según su idioma en 2 df, esto debido a que se entrenan modelos separados para ingles y español para integrar correctamente los lexicones posteriormente según el idioma, luego de esto se separan los df en los datos y etiquetas de prueba, este procedimiento también es independiente para cada idioma, posteriormente se vectorizan los datos tambien segun su idioma y se entrenan y prueban los modelos, en esta etapa se guardan los vocabularios de cada vectorizador aparte y también los modelos, esto con el fin de hacer uso de estos en otro programa posteriormente.\n",
    "\n",
    "Por último se muestran los resultados del modelo entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelos_mourning_supervisados(modelo_entr, df_balanceado, df_lematizado):\n",
    "    from nltk.corpus import stopwords\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    import pandas as pd\n",
    "    import pickle, os, nltk\n",
    "\n",
    "    modelos_es = {\n",
    "        'GBT': AdaBoostClassifier(DecisionTreeClassifier(max_depth=6), n_estimators=4),\n",
    "        'RF': RandomForestClassifier(n_estimators=14, max_depth=28),\n",
    "        'NN': MLPClassifier(hidden_layer_sizes=(30, 2), max_iter=100),\n",
    "        'DT': DecisionTreeClassifier(max_depth=16),\n",
    "        'NB': MultinomialNB()\n",
    "    }\n",
    "\n",
    "    modelos_en = {\n",
    "        'GBT': AdaBoostClassifier(DecisionTreeClassifier(max_depth=6), n_estimators=4),\n",
    "        'RF': RandomForestClassifier(n_estimators=14, max_depth=28),\n",
    "        'NN': MLPClassifier(hidden_layer_sizes=(30, 2), max_iter=100),\n",
    "        'DT': DecisionTreeClassifier(max_depth=16),\n",
    "        'NB': MultinomialNB()\n",
    "    }\n",
    "\n",
    "    if modelo_entr in modelos_es and modelo_entr in modelos_en and 0 <= df_balanceado <= 1 and 0 <= df_lematizado <= 1:\n",
    "\n",
    "        print(\"\")\n",
    "        nltk.download('stopwords')\n",
    "\n",
    "        # ---------------- Asignacion de los modelos y vectorizadores.\n",
    "        # -------- Español.\n",
    "        modelo_es = modelos_es[modelo_entr]\n",
    "        vectorizer_es = TfidfVectorizer(use_idf=True, stop_words=stopwords.words('spanish'))\n",
    "        # -------- Ingles.\n",
    "        modelo_en = modelos_en[modelo_entr]\n",
    "        vectorizer_en = TfidfVectorizer(use_idf=True, stop_words=stopwords.words('english'))\n",
    "\n",
    "        # ---------------- Lectura y separacion de datos.\n",
    "        df = pd.DataFrame(get_mourning_df(df_balanceado, df_lematizado))\n",
    "        # -------- Español.\n",
    "        df_es = df[df.lang == 'es']\n",
    "        # -------- Ingles.\n",
    "        df_en = df[df.lang == 'en']\n",
    "        del df\n",
    "        print(\"Separacion de datos por idioma terminada\")\n",
    "\n",
    "        # ---------------- Separacion en data y labels de entrenamiento.\n",
    "        # -------- Español.\n",
    "        data_train_es, data_test_es, label_train_es, label_test_es = train_test_split(\n",
    "            df_es['text'], df_es['mourning'], random_state=1\n",
    "        )\n",
    "        del df_es\n",
    "        # -------- Ingles.\n",
    "        data_train_en, data_test_en, label_train_en, label_test_en = train_test_split(\n",
    "            df_en['text'], df_en['mourning'], random_state=1\n",
    "        )\n",
    "        print(\"Division de datos terminada\")\n",
    "        del df_en\n",
    "\n",
    "        # ---------------- vectorizacion de los textos.\n",
    "        # -------- Español.\n",
    "        training_data_es = vectorizer_es.fit_transform(data_train_es)\n",
    "        testing_data_es = vectorizer_es.transform(data_test_es)\n",
    "        del data_train_es, data_test_es\n",
    "        print(\"Vectorizacion en español terminada\")\n",
    "        # -------- Ingles.\n",
    "        training_data_en = vectorizer_en.fit_transform(data_train_en)\n",
    "        testing_data_en = vectorizer_en.transform(data_test_en)\n",
    "        del data_test_en, data_train_en\n",
    "        print(\"Vectorizacion en ingles terminada\")\n",
    "\n",
    "        # ---------------- almacenamiento de los vocabularios.\n",
    "        # -------- Español.\n",
    "        ruta_vocabulario_es = \"./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\"\n",
    "        if os.path.exists(ruta_vocabulario_es):\n",
    "            os.remove(ruta_vocabulario_es)\n",
    "        pickle.dump(vectorizer_es.vocabulary_, open(ruta_vocabulario_es, \"wb\"))\n",
    "        print(\"Vocabulario para español almacenado en \" + ruta_vocabulario_es)\n",
    "        # -------- Ingles.\n",
    "        ruta_vocabulario_en = \"./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\"\n",
    "        if os.path.exists(ruta_vocabulario_en):\n",
    "            os.remove(ruta_vocabulario_en)\n",
    "        pickle.dump(vectorizer_en.vocabulary_, open(ruta_vocabulario_en, \"wb\"))\n",
    "        print(\"Vocabulario para ingles almacenado en \" + ruta_vocabulario_en)\n",
    "\n",
    "        # ---------------- entrenamiento y guardado de los modelos.\n",
    "        # -------- Español.\n",
    "        ruta_modelo_es = './entrenamiento de modelos/modelos/' + str(type(modelo_es).__name__) + '_Mourning_es.sav'\n",
    "        modelo_es.fit(training_data_es, label_train_es)\n",
    "        pickle.dump(modelo_es, open(ruta_modelo_es, 'wb'))\n",
    "        print(\"Modelo de \" + str(type(modelo_es).__name__) + \" en español guardado en \" + ruta_modelo_es)\n",
    "        # -------- Ingles.\n",
    "        ruta_modelo_en = './entrenamiento de modelos/modelos/' + str(type(modelo_en).__name__) + '_Mourning_en.sav'\n",
    "        modelo_en.fit(training_data_en, label_train_en)\n",
    "        pickle.dump(modelo_en, open(ruta_modelo_en, 'wb'))\n",
    "        print(\"Modelo de \" + str(type(modelo_en).__name__) + \" en ingles guardado en \" + ruta_modelo_en)\n",
    "\n",
    "        # ---------------- implementacion de los modelos.\n",
    "        # -------- Español.\n",
    "        predictions_es = modelo_es.predict(testing_data_es)\n",
    "        # -------- Ingles.\n",
    "        predictions_en = modelo_en.predict(testing_data_en)\n",
    "        print(\"Predicciones terminadas\")\n",
    "\n",
    "        # ---------------- Resultados de los modelos.\n",
    "        # -------- Español.\n",
    "        print(\"\\nResultados \" + str(type(modelo_es).__name__) + \" Español:\\n\")\n",
    "        print(classification_report(label_test_es, predictions_es))\n",
    "        # -------- Ingles.\n",
    "        print(\"\\nResultados \" + str(type(modelo_en).__name__) + \" Ingles:\\n\")\n",
    "        print(classification_report(label_test_en, predictions_en))\n",
    "\n",
    "    elif modelo_entr not in modelos_es or modelo_entr not in modelos_en or df_balanceado > 1 or df_balanceado < 0 or df_lematizado > 1 or df_lematizado < 0:\n",
    "\n",
    "        print(\"Parametros incorrectos para entrenar modelo\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando df 37.5%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 100.0%\n",
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Lematizando df 100.0%\n",
      "Df mourning entregado\n",
      "\n",
      "Separacion de datos por idioma terminada\n",
      "Division de datos terminada\n",
      "Vectorizacion en español terminada\n",
      "Vectorizacion en ingles terminada\n",
      "Vocabulario para español almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\n",
      "Vocabulario para ingles almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\n",
      "Modelo de MultinomialNB en español guardado en ./entrenamiento de modelos/modelos/MultinomialNB_Mourning_es.sav\n",
      "Modelo de MultinomialNB en ingles guardado en ./entrenamiento de modelos/modelos/MultinomialNB_Mourning_en.sav\n",
      "Predicciones terminadas\n",
      "\n",
      "Resultados MultinomialNB Español:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77      1067\n",
      "           1       0.73      0.92      0.81      1021\n",
      "\n",
      "    accuracy                           0.79      2088\n",
      "   macro avg       0.81      0.80      0.79      2088\n",
      "weighted avg       0.81      0.79      0.79      2088\n",
      "\n",
      "\n",
      "Resultados MultinomialNB Ingles:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75      1053\n",
      "           1       0.73      0.83      0.78      1035\n",
      "\n",
      "    accuracy                           0.76      2088\n",
      "   macro avg       0.77      0.76      0.76      2088\n",
      "weighted avg       0.77      0.76      0.76      2088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelos_mourning_supervisados('NB',1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos DT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando df 37.5%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 100.0%\n",
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Lematizando df 100.0%\n",
      "Df mourning entregado\n",
      "\n",
      "Separacion de datos por idioma terminada\n",
      "Division de datos terminada\n",
      "Vectorizacion en español terminada\n",
      "Vectorizacion en ingles terminada\n",
      "Vocabulario para español almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\n",
      "Vocabulario para ingles almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\n",
      "Modelo de DecisionTreeClassifier en español guardado en ./entrenamiento de modelos/modelos/DecisionTreeClassifier_Mourning_es.sav\n",
      "Modelo de DecisionTreeClassifier en ingles guardado en ./entrenamiento de modelos/modelos/DecisionTreeClassifier_Mourning_en.sav\n",
      "Predicciones terminadas\n",
      "\n",
      "Resultados DecisionTreeClassifier Español:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      1067\n",
      "           1       0.97      0.89      0.93      1021\n",
      "\n",
      "    accuracy                           0.93      2088\n",
      "   macro avg       0.93      0.93      0.93      2088\n",
      "weighted avg       0.93      0.93      0.93      2088\n",
      "\n",
      "\n",
      "Resultados DecisionTreeClassifier Ingles:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      1053\n",
      "           1       0.88      0.74      0.80      1035\n",
      "\n",
      "    accuracy                           0.82      2088\n",
      "   macro avg       0.83      0.82      0.82      2088\n",
      "weighted avg       0.83      0.82      0.82      2088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelos_mourning_supervisados('DT',1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando df 50.0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 100.0%\n",
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Lematizando df 100.0%\n",
      "Df mourning entregado\n",
      "\n",
      "Separacion de datos por idioma terminada\n",
      "Division de datos terminada\n",
      "Vectorizacion en español terminada\n",
      "Vectorizacion en ingles terminada\n",
      "Vocabulario para español almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\n",
      "Vocabulario para ingles almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\n",
      "Modelo de RandomForestClassifier en español guardado en ./entrenamiento de modelos/modelos/RandomForestClassifier_Mourning_es.sav\n",
      "Modelo de RandomForestClassifier en ingles guardado en ./entrenamiento de modelos/modelos/RandomForestClassifier_Mourning_en.sav\n",
      "Predicciones terminadas\n",
      "\n",
      "Resultados RandomForestClassifier Español:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1067\n",
      "           1       0.90      0.71      0.79      1021\n",
      "\n",
      "    accuracy                           0.82      2088\n",
      "   macro avg       0.83      0.82      0.82      2088\n",
      "weighted avg       0.83      0.82      0.82      2088\n",
      "\n",
      "\n",
      "Resultados RandomForestClassifier Ingles:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.80      1053\n",
      "           1       0.82      0.74      0.78      1035\n",
      "\n",
      "    accuracy                           0.79      2088\n",
      "   macro avg       0.80      0.79      0.79      2088\n",
      "weighted avg       0.80      0.79      0.79      2088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelos_mourning_supervisados('RF',1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos GBT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando df 37.5%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 100.0%\n",
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Lematizando df 100.0%\n",
      "Df mourning entregado\n",
      "\n",
      "Separacion de datos por idioma terminada\n",
      "Division de datos terminada\n",
      "Vectorizacion en español terminada\n",
      "Vectorizacion en ingles terminada\n",
      "Vocabulario para español almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\n",
      "Vocabulario para ingles almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\n",
      "Modelo de AdaBoostClassifier en español guardado en ./entrenamiento de modelos/modelos/AdaBoostClassifier_Mourning_es.sav\n",
      "Modelo de AdaBoostClassifier en ingles guardado en ./entrenamiento de modelos/modelos/AdaBoostClassifier_Mourning_en.sav\n",
      "Predicciones terminadas\n",
      "\n",
      "Resultados AdaBoostClassifier Español:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1067\n",
      "           1       0.95      0.91      0.93      1021\n",
      "\n",
      "    accuracy                           0.93      2088\n",
      "   macro avg       0.93      0.93      0.93      2088\n",
      "weighted avg       0.93      0.93      0.93      2088\n",
      "\n",
      "\n",
      "Resultados AdaBoostClassifier Ingles:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1053\n",
      "           1       0.85      0.78      0.81      1035\n",
      "\n",
      "    accuracy                           0.82      2088\n",
      "   macro avg       0.82      0.82      0.82      2088\n",
      "weighted avg       0.82      0.82      0.82      2088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelos_mourning_supervisados('GBT',1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparando df 50.0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando df 100.0%\n",
      "Normalizando df 100.0%\n",
      "Creando sellos de balanceamiento 100.0%\n",
      "Balanceando df\n",
      "Lematizando df 100.0%\n",
      "Df mourning entregado\n",
      "\n",
      "Separacion de datos por idioma terminada\n",
      "Division de datos terminada\n",
      "Vectorizacion en español terminada\n",
      "Vectorizacion en ingles terminada\n",
      "Vocabulario para español almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_es.pkl\n",
      "Vocabulario para ingles almacenado en ./entrenamiento de modelos/vocabularios/vocabulario_mourning_en.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/Documentos/PytonVenv/venv_nlp/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de MLPClassifier en español guardado en ./entrenamiento de modelos/modelos/MLPClassifier_Mourning_es.sav\n",
      "Modelo de MLPClassifier en ingles guardado en ./entrenamiento de modelos/modelos/MLPClassifier_Mourning_en.sav\n",
      "Predicciones terminadas\n",
      "\n",
      "Resultados MLPClassifier Español:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.64      0.76      1067\n",
      "           1       0.72      0.96      0.82      1021\n",
      "\n",
      "    accuracy                           0.79      2088\n",
      "   macro avg       0.83      0.80      0.79      2088\n",
      "weighted avg       0.83      0.79      0.79      2088\n",
      "\n",
      "\n",
      "Resultados MLPClassifier Ingles:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1053\n",
      "           1       0.79      0.64      0.71      1035\n",
      "\n",
      "    accuracy                           0.74      2088\n",
      "   macro avg       0.75      0.74      0.74      2088\n",
      "weighted avg       0.75      0.74      0.74      2088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/Documentos/PytonVenv/venv_nlp/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "entrenar_modelos_mourning_supervisados('NN',1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
